{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the scipy.misc package is deprecated for image reading the imageio is used below ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#from scipy.misc import imread, imresize\n",
    "#from scipy.misc.pilutil import imread\n",
    "import imageio\n",
    "#import cv2\n",
    "import datetime\n",
    "import os\n",
    "from PIL import Image \n",
    "from tensorflow.keras.layers import Dropout,LSTM,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import GlobalAveragePooling3D\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "#tf.set_random_seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Size for each Training experiment is set to 16 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('/datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/datasets/Project_data/val.csv').readlines())\n",
    "#train_doc = np.random.permutation(open('/content/drive/My Drive/Final_data/Collated_training/train.csv').readlines())\n",
    "#val_doc = np.random.permutation(open('/content/drive/My Drive/Final_data/Collated_training/val.csv').readlines())\n",
    "batch_size = 16 #experiment with the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = list(range(0, 30)) #create a list of image numbers you want to use for a particular video\n",
    "\n",
    "    x = 30  # Number of frames per video\n",
    "    y = 180  # Image height after resizing\n",
    "    z = 180\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(t) // batch_size  # Calculate the number of full batches\n",
    "        remaining_samples = len(t) % batch_size  \n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.uint8)\n",
    "                    image_pil = Image.fromarray(image)\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image_resized = np.array(image_pil.resize((y, z)))\n",
    "\n",
    "                    # Normalize the image (scale pixel values to [0, 1]) and assign to batch_data\n",
    "                    batch_data[folder,idx, :, :, 0] = image_resized[:, :, 0] / 255.0  # Red channel\n",
    "                    batch_data[folder,idx, :, :, 1] = image_resized[:, :, 1] / 255.0  # Green channel\n",
    "                    batch_data[folder,idx, :, :, 2] = image_resized[:, :, 2] / 255.0  # Blue channel\n",
    "                    \n",
    "                    batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "    if remaining_samples > 0:\n",
    "            batch_data = np.zeros((remaining_samples, x, y, z, 3))  # Initialize batch data for the remaining samples\n",
    "            batch_labels = np.zeros((remaining_samples, 5))  # Initialize batch labels for the remaining samples\n",
    "            \n",
    "            for folder in range(remaining_samples):  # Iterate over the remaining samples\n",
    "                folder_name = t[num_batches * batch_size + folder].split(';')[0]  # Get folder name\n",
    "                imgs = os.listdir(os.path.join(source_path, folder_name))  # Get all images in the folder\n",
    "                \n",
    "                for idx, item in enumerate(img_idx):  # Iterate over the frames/images of the folder\n",
    "                    image_path = os.path.join(source_path, folder_name, imgs[item])\n",
    "                    image = imageio.imread(image_path).astype(np.uint8)  # Read and convert the image to float32\n",
    "            \n",
    "                    # Resize and normalize the image\n",
    "                    image_resized = np.array(image_pil.resize((y, z)))  # Resize the image to the desired shape\n",
    "                    \n",
    "                    # Normalize the image channels (R, G, B)\n",
    "                    batch_data[folder, idx, :, :, 0] = image_resized[:, :, 0] / 255.0  # Red channel\n",
    "                    batch_data[folder, idx, :, :, 1] = image_resized[:, :, 1] / 255.0  # Green channel\n",
    "                    batch_data[folder, idx, :, :, 2] = image_resized[:, :, 2] / 255.0  # Blue channel\n",
    "                \n",
    "                # One-hot encode the label for the remaining sample\n",
    "                label = int(t[num_batches * batch_size + folder].split(';')[2])  # Extract the label\n",
    "                batch_labels[folder, label] = 1  # Set the label for the remaining sample\n",
    "            \n",
    "            # Yield the remaining data and labels\n",
    "            yield batch_data, batch_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above generator function we have below implementation done \n",
    "1.Resizing of image to 180 * 180 \n",
    "2.Normalised the images as batches of 16\n",
    "3.Remaining sample variable was set and code to normalise was done\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/datasets/Project_data/train'\n",
    "val_path = '/datasets/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs =  20  # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epoch was set to 20 though it has to be set higher for better results , for computational reasons reduced to  20 in this case ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "#write your model here\n",
    "model = Sequential()\n",
    "\n",
    "x, y, z = 30, 180, 180  # Input dimensions: (frames, height, width)\n",
    "\n",
    "# Layer 1: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z, 3)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    " \n",
    "# Layer 3: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "# Global Average Pooling to Reduce Dimensions\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM Layer for Temporal Dynamics\n",
    "model.add(LSTM(64, return_sequences=False,kernel_regularizer=l2(0.01), dropout=0.5))\n",
    "\n",
    "# Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dense Layers\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above final model \n",
    "1. 3 layers of Convo3D with 32,32 and 64 size respectively and activation layer with relu\n",
    "2. Dropout of 20% was added to minimise unwanted neuron connection and improve validation accuracy\n",
    "3. Global Average pooling caused reshaping issues with LSTM inclusion finally ,so we  used TimeDistributed Flatten  to reduce dimensions\n",
    "4. LSTM layer was applied finally to improve accuracy with Regulariser  of  0.01 and drop out of 0.5\n",
    "5. Batch Normalisation and Dense methods were added to improve accuracy.\n",
    "6. Final Dense layer with activation function of softmax was included to find exact match of the 5 gesture images of the  Assignment\n",
    "####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam Optimiser summary of the model are below ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_22 (Conv3D)          (None, 28, 178, 178, 32)  2624      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 28, 178, 178, 32)  0         \n",
      "                                                                 \n",
      " max_pooling3d_21 (MaxPoolin  (None, 14, 89, 89, 32)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_23 (Conv3D)          (None, 12, 87, 87, 32)    27680     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 12, 87, 87, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d_22 (MaxPoolin  (None, 6, 43, 43, 32)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_24 (Conv3D)          (None, 4, 41, 41, 64)     55360     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 4, 41, 41, 64)     0         \n",
      "                                                                 \n",
      " max_pooling3d_23 (MaxPoolin  (None, 2, 20, 20, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 2, 20, 20, 64)     0         \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 2, 25600)         0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                6570240   \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,674,085\n",
      "Trainable params: 6,673,957\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#optimiser = SGD(learning_rate=0.01, momentum=0.9)#write your optimizer\n",
    "optimiser = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(\n",
    "    monitor='val_loss',          # Metric to monitor (can be 'val_loss', 'loss', etc.)\n",
    "    factor=0.2,                  # Factor by which to reduce the learning rate\n",
    "    patience=5,                  # Number of epochs with no improvement before reducing learning rate\n",
    "    min_lr=1e-6,                 # Minimum learning rate (to avoid going too low)\n",
    "    verbose=1                    # Display messages when the learning rate is reduced\n",
    ")\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model generated with accuracy of 93% and validation accuracy of 86% ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are experiments done to tune the Model and improve accuracy ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At first used Sgd Optimiser and the accuracy resulted was 20% only ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" with. Sgd Optimizer and below netwrok architecture we get 20% accuracy\n",
    "\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(5, activation='softmax')) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam optimiser was used , Batch Normalisation after each layer  was removed and only was included in the  final layer of size 128.\n",
    "#### Flatten and Dense layers were used with drop out of 0.4\n",
    "#### Accuracy was thus was 71% and  Validation accuracy of 55%\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" with adam optimiser and below. architecture categorical accuracy is 0.7128  and validation accuracy 0.5536\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z,3)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(5, activation='softmax'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the Flatten  and Dense layers used GlobalAveragepooling but the accuracy is 80% and validation accuracy is 69% ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" with adam optimiser and below. architecture categorical accuracy is 0.8051 and validation accuracy 0.6964\n",
    "model = Sequential()\n",
    "\n",
    "x = 30  # Number of frames per video\n",
    "y = 180  # Image height after resizing\n",
    "z = 180\n",
    "# Layer 1\n",
    "\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z,3)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(GlobalAveragePooling3D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(5, activation='softmax'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Distributed Flatten was used in Flatten and Dense layers along with GRU but the accuracy was 47% and validation accuracy was 43% ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" with adam optimiser and below. architecture categorical accuracy is 0.4732  and validation accuracy 0.4375\n",
    "model = Sequential()\n",
    "\n",
    "x = 30  # Number of frames per video\n",
    "y = 180  # Image height after resizing\n",
    "z = 180\n",
    "# Layer 1\n",
    "\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z,3)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(GRU(64, return_sequences=False))\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM was in corporated in code with filter size as 128 and resulted in overfitting ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" with adam optimiser and below. architecture categorical accuracy is 1.00  and validation accuracy 0.66\n",
    "model = Sequential()\n",
    "\n",
    "x, y, z = 30, 180, 180  # Input dimensions: (frames, height, width)\n",
    "\n",
    "# Layer 1: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z, 3)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 3: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Global Average Pooling to Reduce Dimensions\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM Layer for Temporal Dynamics\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "\n",
    "# Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dense Layers\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(5, activation='softmax'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM was run again with filter size of 64 and the accuracy was 99% and Validation accuracy of 70% ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  with adam optimiser and below. architecture categorical accuracy is 0.9940  and validation accuracy 0.70\n",
    "model = Sequential()\n",
    "\n",
    "x, y, z = 30, 180, 180  # Input dimensions: (frames, height, width)\n",
    "\n",
    "# Layer 1: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z, 3)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 3: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Global Average Pooling to Reduce Dimensions\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM Layer for Temporal Dynamics\n",
    "model.add(LSTM(64, return_sequences=False,kernel_regularizer=l2(0.01), dropout=0.4))\n",
    "\n",
    "# Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dense Layers\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5, activation='softmax'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 3 Convo3D filter size was reduced to 64 and LSTM dropout was updated to 0.4 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"with adam optimiser and below. architecture categorical accuracy is 0.9926  and validation accuracy 0.75\n",
    "model = Sequential()\n",
    "model = Sequential()\n",
    "\n",
    "x, y, z = 30, 180, 180  # Input dimensions: (frames, height, width)\n",
    "\n",
    "# Layer 1: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z, 3)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 3: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Global Average Pooling to Reduce Dimensions\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM Layer for Temporal Dynamics\n",
    "model.add(LSTM(64, return_sequences=False,kernel_regularizer=l2(0.01), dropout=0.4))\n",
    "\n",
    "# Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dense Layers\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM drop out parameter was set to 0.5 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"with adam optimiser and below. architecture categorical accuracy is 0.9301  and validation accuracy 0.7500\n",
    "model = Sequential()\n",
    "\n",
    "x, y, z = 30, 180, 180  # Input dimensions: (frames, height, width)\n",
    "\n",
    "# Layer 1: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z, 3)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# Layer 2: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# Layer 3: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "# Global Average Pooling to Reduce Dimensions\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM Layer for Temporal Dynamics\n",
    "model.add(LSTM(64, return_sequences=False,kernel_regularizer=l2(0.01), dropout=0.5))\n",
    "\n",
    "# Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dense Layers\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" with adam optimiser and below. architecture categorical accuracy is 0.9330  and validation accuracy 0.8661\n",
    "model = Sequential()\n",
    "\n",
    "x, y, z = 30, 180, 180  # Input dimensions: (frames, height, width)\n",
    "\n",
    "# Layer 1: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(x, y, z, 3)))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# Layer 2: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    " \n",
    "# Layer 3: Conv3D + MaxPooling3D\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "# Global Average Pooling to Reduce Dimensions\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM Layer for Temporal Dynamics\n",
    "model.add(LSTM(64, return_sequences=False,kernel_regularizer=l2(0.01), dropout=0.5))\n",
    "\n",
    "# Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dense Layers\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
